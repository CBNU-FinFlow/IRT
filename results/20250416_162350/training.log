2025-04-16 16:23:50,843 - INFO - 결과 저장 폴더: results/20250416_162350
2025-04-16 16:23:50,843 - INFO - 
=============== 시스템 환경 확인 ===============
2025-04-16 16:23:50,843 - INFO -  사용 디바이스: cuda:0
2025-04-16 16:23:50,843 - INFO -  CUDA 버전: 11.8
2025-04-16 16:23:50,916 - INFO -  GPU: NVIDIA RTX A5000
2025-04-16 16:23:50,923 - INFO -  GPU 사용률: 10% / 메모리 사용률: 1%
2025-04-16 16:23:50,923 - INFO - ================================================
2025-04-16 16:23:50,923 - INFO - 
================== 데이터 준비 ==================
2025-04-16 16:23:50,925 - INFO - 캐시 로드 완료. Shape: (4278, 10, 10)
2025-04-16 16:23:50,925 - INFO -  훈련 데이터: (3274, 10, 10) (2008-01-02 ~ 2020-12-31)
2025-04-16 16:23:50,925 - INFO -  테스트 데이터: (1004, 10, 10) (2021-01-04 ~ 2024-12-30)
2025-04-16 16:23:50,925 - INFO - ================================================
2025-04-16 16:23:50,925 - INFO - 
============== 환경 및 에이전트 설정 ==============
2025-04-16 16:23:50,926 - INFO -  환경 설정: 자산 수=10, 피처 수=10
2025-04-16 16:23:51,854 - INFO -  PPO 에이전트 생성 완료 (lr=0.0001)
2025-04-16 16:23:51,854 - INFO - ================================================
2025-04-16 16:23:51,854 - INFO - 
================ PPO 에이전트 학습 ================
2025-04-16 16:23:51,854 - INFO - PPO 학습 시작: 500 에피소드, 에피소드당 최대 200 스텝
2025-04-16 16:23:51,854 - INFO - 정책 업데이트 주기: 2000 스텝
2025-04-16 16:23:52,306 - INFO - 새로운 최고 성능 모델 저장! 에피소드: 0, 보상: -0.8105 -> models/best_model.pth
2025-04-16 16:23:52,521 - INFO - 새로운 최고 성능 모델 저장! 에피소드: 1, 보상: -0.6566 -> models/best_model.pth
2025-04-16 16:23:52,727 - INFO - 새로운 최고 성능 모델 저장! 에피소드: 2, 보상: -0.3722 -> models/best_model.pth
2025-04-16 16:23:54,780 - INFO - 새로운 최고 성능 모델 저장! 에피소드: 11, 보상: -0.3034 -> models/best_model.pth
2025-04-16 16:23:56,872 - INFO - 새로운 최고 성능 모델 저장! 에피소드: 21, 보상: -0.2695 -> models/best_model.pth
2025-04-16 16:24:06,088 - INFO - 새로운 최고 성능 모델 저장! 에피소드: 68, 보상: 0.0225 -> models/best_model.pth
2025-04-16 16:25:39,242 - INFO - 
총 학습 시간: 107.39초 (0.0011초/스텝)
2025-04-16 16:25:39,242 - INFO - 학습 환경의 상태 정규화(obs_rms) 통계를 에이전트에 저장했습니다.
2025-04-16 16:25:39,242 - INFO -  PPO 학습 완료!
2025-04-16 16:25:39,242 - INFO - ================================================
2025-04-16 16:25:39,242 - INFO - 
================ PPO 에이전트 평가 ================
2025-04-16 16:25:39,249 - INFO - 모델 로드 성공! (models/best_model.pth), 최고 보상: 0.0225
2025-04-16 16:25:39,249 - INFO - PPO 에이전트 평가 시작 (결정론적 행동)...
2025-04-16 16:25:39,411 - INFO - 평가 종료. 총 스텝: 266
2025-04-16 16:25:39,411 - INFO -  테스트 완료!
2025-04-16 16:25:39,411 - INFO - ================================================
2025-04-16 16:25:39,411 - INFO - 
============= 성능 분석 및 시각화 =============
2025-04-16 16:25:39,411 - INFO - --- 포트폴리오 성능 지표 ---
2025-04-16 16:25:39,411 - INFO -  연간 수익률: 32.64%
2025-04-16 16:25:39,411 - INFO -  연간 변동성: 16.91%
2025-04-16 16:25:39,412 - INFO -  샤프 비율: 1.93
2025-04-16 16:25:39,412 - INFO -  최대 낙폭: 12.83%
2025-04-16 16:25:39,412 - INFO -  칼마 비율: 2.54
2025-04-16 16:25:39,412 - INFO -  테스트 기간 총 Raw 보상: 0.3292
2025-04-16 16:25:39,985 - INFO - 성능 그래프 저장 완료: results/20250416_162350/PPO_performance.png
2025-04-16 16:25:39,986 - INFO - ================================================
2025-04-16 16:25:39,986 - INFO - 
============ 설명 가능한 AI (XAI) 분석 ============
2025-04-16 16:25:39,986 - INFO -  DRL 에이전트 특성 가중치 계산 중...
2025-04-16 16:25:53,559 - INFO -  참조 모델(선형 회귀) 특성 가중치 계산 중...
2025-04-16 16:25:54,405 - INFO -  DRL과 참조 모델 평균 특성 중요도 상관계수: -1.0000
2025-04-16 16:25:54,814 - INFO -  XAI 분석 완료!
2025-04-16 16:25:54,815 - INFO - ================================================
2025-04-16 16:25:54,815 - INFO - 
===== 프로그램 종료 =====
