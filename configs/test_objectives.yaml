# 고급 보상 함수 테스트용 설정

seed: 42
device: cpu

# 데이터 설정
data:
  symbols: ['AAPL', 'MSFT', 'GOOGL']

  # 날짜 기반 설정
  start: "2023-01-01"      # 전체 데이터 시작
  end: "2024-06-30"        # train+val 종료
  test_start: "2024-07-01" # 테스트 시작
  test_end: "2024-12-31"   # 테스트 종료
  val_ratio: 0.2           # train에서 val 분리 비율
  interval: '1d'
  cache: true

# 환경 설정
env:
  initial_balance: 1000000
  transaction_cost: 0.001
  max_leverage: 1.0
  window_size: 20

# 목적함수 설정 (PortfolioObjective) - 고급 보상 함수 활성화
objectives:
  # Differential Sharpe
  sharpe_beta: 1.0
  sharpe_ema_alpha: 0.99
  sharpe_epsilon: 1.0e-8

  # CVaR 제약
  cvar_alpha: 0.05
  cvar_target: -0.02
  lambda_cvar: 1.0

  # 추가 페널티
  lambda_turn: 0.1
  lambda_dd: 0.0

  # 보상 정규화
  r_clip: 5.0
  reward_ema_alpha: 0.99

# 오프라인 학습
offline:
  method: 'td3bc'
  epochs: 1
  batch_size: 256
  expectile: 0.7
  temperature: 3.0
  bc_weight: 2.5
  policy_delay: 2
  normalize_q: true

# B-Cell 설정
bcell:
  algorithm: 'REDQ'
  hidden_dims: [256, 256]
  n_critics: 10
  m_sample: 2
  utd_ratio: 20
  actor_lr: 3e-4
  critic_lr: 3e-4
  alpha_lr: 3e-4
  batch_size: 256
  gamma: 0.99
  tau: 0.005
  alpha: 0.2
  crisis_threshold: 0.7
  buffer_size: 100000

# T-Cell 설정
tcell:
  contamination: 0.1
  n_estimators: 100
  window_size: 100

# Memory Cell 설정
memory:
  capacity: 1000
  k_neighbors: 5

# 온라인 학습
online_episodes: 2  # 빠른 테스트
skip_offline: false
early_stopping_patience: 20

# 평가 설정
validation_freq: 1
save_freq: 100

# Ablation 설정
ablation:
  use_tcell: true
  use_memory: true
  use_xai: false
  offline_method: 'td3bc'

# 로깅
log_level: 'INFO'